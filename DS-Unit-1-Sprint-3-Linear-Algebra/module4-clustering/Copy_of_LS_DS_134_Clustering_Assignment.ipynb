{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_134_Clustering_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cal-0/Cal-0-dashboard.github.io/blob/master/DS-Unit-1-Sprint-3-Linear-Algebra/module4-clustering/Copy_of_LS_DS_134_Clustering_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3rVFtGLMJM",
        "colab_type": "text"
      },
      "source": [
        "# K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VS3FFSFLR3a",
        "colab_type": "text"
      },
      "source": [
        "# 1) Use the \"Breast Cancer Wisconsin (Diagnostic) Data Set\" from Kaggle to try and cluster types of cancer cells. \n",
        "\n",
        "Here's the original dataset for your reference:\n",
        "\n",
        "<https://www.kaggle.com/uciml/breast-cancer-wisconsin-data>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899RK3bBn4OE",
        "colab_type": "text"
      },
      "source": [
        "## This is a supervised learning dataset\n",
        "\n",
        "(Because it has **labels** - The \"diagnosis\" column.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws5R9X6hLJQ2",
        "colab_type": "code",
        "outputId": "0e075550-8ac1-417c-b550-e79e0705e83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA # You don't necessarily have to use this\n",
        "from sklearn.cluster import KMeans # You don't necessarily have to use this\n",
        "from sklearn.preprocessing import StandardScaler # You don't necessarily have to use this\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/Cancer_Cells.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 33)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHDDqaU-ove4",
        "colab_type": "text"
      },
      "source": [
        "## Now it's an unsupervised learning dataset\n",
        "\n",
        "(Because we've removed the diagnosis label) - Use this version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86MHoPJon_aC",
        "colab_type": "code",
        "outputId": "5e289d24-4a72-47e7-c9f2-f4ec7378fe01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "df = df.drop('diagnosis', axis=1)\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  radius_mean  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302        17.99  ...                  0.11890          NaN\n",
              "1    842517        20.57  ...                  0.08902          NaN\n",
              "2  84300903        19.69  ...                  0.08758          NaN\n",
              "3  84348301        11.42  ...                  0.17300          NaN\n",
              "4  84358402        20.29  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rskC80k3OKMA",
        "colab_type": "text"
      },
      "source": [
        "## Let's do it!\n",
        "\n",
        "- You might want to do some data exploration to see if you can find specific columns that will help you find distinct clusters of cells\n",
        "- You might want to use the elbow method to decide on the number of clusters to use.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U92Y3jNKPpjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform K-Means Clustering on the Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMbhYQdPta1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.replace({np.NaN: 0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_SNsqRTtCt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_of_squared_distances = []\n",
        "K = range(1,15)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km = km.fit(df)\n",
        "    sum_of_squared_distances.append(km.inertia_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLZCFRnktCrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1e44b004-7c30-4135-a122-8e50abd4fbed"
      },
      "source": [
        "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Sum_of_squared_distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEWCAYAAACDoeeyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc5I3M6ux/w+WwN1xFjEb7AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIPFLWO1Ehjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-054hQtEPv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mat = df.values\n",
        "km = sklearn.cluster.KMeans(n_clusters=2)\n",
        "km.fit(mat)\n",
        "labels = km.labels_\n",
        "results = pd.DataFrame([df.index,labels]).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr-Cd1U2ExP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "8ae92f04-225d-4a82-cff9-8b980a814b3a"
      },
      "source": [
        "results"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>564</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>565</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>566</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>567</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>568</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1\n",
              "0      0  0\n",
              "1      1  0\n",
              "2      2  0\n",
              "3      3  0\n",
              "4      4  0\n",
              "..   ... ..\n",
              "564  564  0\n",
              "565  565  0\n",
              "566  566  0\n",
              "567  567  0\n",
              "568  568  0\n",
              "\n",
              "[569 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzM1-R-itCl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "0ff8eee1-e15a-49df-e563-c45dcfc6dcff"
      },
      "source": [
        "plt.scatter(results, results(1))\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-44c4976053cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr-5QuOmtCiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUUB8nXVtCPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ghqYSxrP_FE",
        "colab_type": "text"
      },
      "source": [
        "## Check you work: \n",
        "\n",
        "This is something that in a truly unsupervised learning situation **WOULD NOT BE POSSIBLE**. But for educational purposes go back and grab the true diagnosis column (label) from the original dataset. Take your cluster labels and compare them to the original diagnosis column. You can make scatterplots for each to see how they compare or you can calculate a percent accuracy score like: \n",
        "\\begin{align}\n",
        "\\frac{\\text{Num Correct Labels}}{\\text{Num Total Observations}}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIG7-yGLP-eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BedOTS0eJ9_K",
        "colab_type": "text"
      },
      "source": [
        "# 2) Perform PCA on your dataset first and *then* use k-means clustering. \n",
        "\n",
        "- You need to standardize your data before PCA.\n",
        "- First try clustering just on PC1 and PC2 so that you can make a scatterplot of your clustering.\n",
        "- Then use use a scree plot to decide how many principal components to include in your clustering, and use however many principal components you need in order to retain 90% of the variation of the original dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW1AeAK8PNah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrfbzfBROpP",
        "colab_type": "text"
      },
      "source": [
        "## Check your work: \n",
        "\n",
        "- Compare your PC1, PC2 clustering scatterplot to the clustering scatterplots you made on the raw data\n",
        "- Calculate accuracy scores for both the PC1,PC2 Principal component clustering and the 90% of explained variance clustering.\n",
        "\n",
        "How do your accuracy scores -when preprocessing the data with PCA- compare to the accuracy when simply clustering on the raw data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKBwVaGOOYsq",
        "colab_type": "text"
      },
      "source": [
        "# Stretch Goals:\n",
        "\n",
        "- Study for the Sprint Challenge\n",
        "- Work on your Data Storytelling Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p2djjY5LNWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}